# Telegram Integration System

## Overview

The Telegram integration system represents a modern, sophisticated message processing pipeline that provides seamless interaction between users and the AI system. Built around a unified 5-step processing architecture, it replaces a previous monolithic 1,994-line handler with a clean, modular design that achieves 91% complexity reduction while adding advanced features like sophisticated emoji reactions, automated error recovery, and comprehensive security controls.

## Client Architecture

### TelegramClient Design

The `TelegramClient` serves as the primary orchestrator for all Telegram interactions:

```python
class TelegramClient:
    """Modern Telegram client with session isolation and advanced features"""
    
    def __init__(self):
        self.api_id = int(os.getenv('TELEGRAM_API_ID'))
        self.api_hash = os.getenv('TELEGRAM_API_HASH')
        self.session_name = "telegram_session"
        
        # Session isolation to prevent database conflicts
        self.session_dir = Path("telegram_sessions")
        self.session_dir.mkdir(exist_ok=True)
        
        # Active handler tracking for graceful shutdown
        self._active_handlers = set()
        self._shutdown_requested = False
        
        # Integration components
        self.message_processor = UnifiedMessageProcessor()
        self.missed_message_manager = MissedMessageIntegration()
        
    async def start(self):
        """Initialize client with comprehensive setup"""
        # Initialize Pyrogram client
        self.client = Client(
            self.session_name,
            api_id=self.api_id,
            api_hash=self.api_hash,
            workdir=str(self.session_dir)
        )
        
        await self.client.start()
        
        # Perform self-ping test
        await self.perform_self_ping()
        
        # Register message handler
        self.client.add_handler(MessageHandler(self.handle_message))
        
        logger.info("‚úÖ Telegram client started successfully")
```

### Session Management

**Session Isolation Strategy**:
```python
class SessionManager:
    """Manages Telegram session lifecycle"""
    
    def __init__(self):
        # Use dedicated session directory
        self.session_dir = Path("telegram_sessions")
        self.session_file = self.session_dir / "telegram_session.session"
        
    def migrate_legacy_session(self):
        """Migrate from old session locations"""
        legacy_paths = [
            Path("telegram_session.session"),
            Path("sessions/telegram_session.session")
        ]
        
        for legacy_path in legacy_paths:
            if legacy_path.exists():
                logger.info(f"Migrating session from {legacy_path}")
                shutil.move(str(legacy_path), str(self.session_file))
                break
    
    def cleanup_sessions(self):
        """Clean up orphaned session files"""
        for session_file in self.session_dir.glob("*.session*"):
            # Check if session is active
            if not self.is_session_active(session_file):
                session_file.unlink()
                logger.info(f"Cleaned up inactive session: {session_file}")
```

### Connection Management

**Reconnection Logic**:
```python
class ConnectionManager:
    """Handles connection resilience and recovery"""
    
    async def handle_connection_error(self, error: Exception):
        """Sophisticated connection error handling"""
        
        if isinstance(error, NetworkError):
            # Network issues - retry with backoff
            await self.retry_with_backoff(max_attempts=5)
            
        elif isinstance(error, ApiIdInvalidError):
            # Invalid credentials - critical error
            logger.critical("Invalid Telegram API credentials")
            raise SystemExit(1)
            
        elif isinstance(error, FloodWait):
            # Rate limited - wait specified time
            wait_time = error.x
            logger.warning(f"Rate limited, waiting {wait_time}s")
            await asyncio.sleep(wait_time)
            
        else:
            # Unknown error - log and retry
            logger.error(f"Connection error: {error}", exc_info=True)
            await asyncio.sleep(10)
    
    async def retry_with_backoff(self, max_attempts: int = 3):
        """Exponential backoff retry strategy"""
        for attempt in range(max_attempts):
            try:
                await self.client.start()
                return
            except Exception as e:
                wait_time = 2 ** attempt
                logger.warning(f"Retry {attempt+1}/{max_attempts} in {wait_time}s")
                await asyncio.sleep(wait_time)
                if attempt == max_attempts - 1:
                    raise e
```

## Handler System

### Unified Message Processing

The handler system uses a clean 5-step pipeline:

```python
class UnifiedMessageProcessor:
    """Main message processing orchestrator"""
    
    def __init__(self):
        self.security_gate = SecurityGate()
        self.context_builder = ContextBuilder()
        self.type_router = TypeRouter()
        self.agent_orchestrator = AgentOrchestrator()
        self.response_manager = ResponseManager()
        self.reaction_manager = ReactionManager()
        
    async def process_message(self, client: Client, message: Message):
        """Process any message through unified pipeline"""
        
        # Track active handler
        handler_id = f"{message.chat.id}_{message.id}"
        client._active_handlers.add(handler_id)
        
        try:
            # Step 1: Security validation
            access_result = self.security_gate.validate_access(message)
            if not access_result.allowed:
                return
            
            # Step 2: Build comprehensive context
            context = await self.context_builder.build_context(message)
            
            # Step 3: Route message and determine strategy
            plan = self.type_router.route_message(context)
            
            # Step 4: Process with AI agent
            response = await self.agent_orchestrator.process_with_agent(context, plan)
            
            # Step 5: Deliver response
            await self.response_manager.deliver_response(response, context, client)
            
        except Exception as e:
            logger.error(f"Pipeline error: {e}", exc_info=True)
            await self.handle_pipeline_error(e, message, client)
            
        finally:
            # Remove handler tracking
            client._active_handlers.discard(handler_id)
```

### Handler Lifecycle Management

```python
class HandlerLifecycleManager:
    """Manages handler registration and lifecycle"""
    
    def register_handlers(self, client: Client):
        """Register all message handlers"""
        
        # Main message handler
        client.add_handler(MessageHandler(
            self.process_message,
            filters=~filters.bot  # Ignore bot messages
        ))
        
        # Edited message handler
        client.add_handler(MessageHandler(
            self.process_edited_message,
            filters=filters.edited & ~filters.bot
        ))
        
        # Callback query handler for inline keyboards
        client.add_handler(CallbackQueryHandler(
            self.handle_callback_query
        ))
    
    async def graceful_shutdown(self, client: Client):
        """Wait for active handlers before shutdown"""
        
        if client._active_handlers:
            logger.info(f"Waiting for {len(client._active_handlers)} active handlers...")
            
            # Wait up to 30 seconds for handlers to complete
            for _ in range(30):
                if not client._active_handlers:
                    break
                await asyncio.sleep(1)
            
            if client._active_handlers:
                logger.warning(f"Forced shutdown with {len(client._active_handlers)} active handlers")
```

## Chat History Management

### ChatHistoryManager Architecture

```python
class ChatHistoryManager:
    """Manages conversation history with LLM-optimized formatting"""
    
    def __init__(self):
        self.db_path = Path("system.db")
        
    async def store_message(self, message: Message, response: str = None):
        """Store message with deduplication"""
        
        async with aiosqlite.connect(self.db_path) as db:
            # Check for duplicates
            existing = await db.execute(
                "SELECT id FROM chat_messages WHERE message_id = ? AND chat_id = ?",
                (message.id, message.chat.id)
            ).fetchone()
            
            if existing:
                return  # Skip duplicate
            
            # Store message
            await db.execute("""
                INSERT INTO chat_messages (
                    chat_id, message_id, user_id, username, 
                    message_text, message_type, timestamp,
                    response_text, media_info
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                message.chat.id,
                message.id,
                message.from_user.id,
                message.from_user.username,
                message.text,
                self.get_message_type(message),
                message.date,
                response,
                self.extract_media_info(message)
            ))
            
            await db.commit()
    
    async def get_recent_history(self, chat_id: int, limit: int = 10) -> List[Dict]:
        """Get recent chat history formatted for LLM context"""
        
        async with aiosqlite.connect(self.db_path) as db:
            cursor = await db.execute("""
                SELECT username, message_text, response_text, timestamp, message_type
                FROM chat_messages 
                WHERE chat_id = ? 
                ORDER BY timestamp DESC 
                LIMIT ?
            """, (chat_id, limit))
            
            rows = await cursor.fetchall()
            
            # Format for LLM consumption
            history = []
            for row in reversed(rows):  # Reverse to chronological order
                username, text, response, timestamp, msg_type = row
                
                # User message
                if text:
                    history.append({
                        "role": "user",
                        "content": f"{username}: {text}",
                        "timestamp": timestamp,
                        "type": msg_type
                    })
                
                # Assistant response
                if response:
                    history.append({
                        "role": "assistant", 
                        "content": response,
                        "timestamp": timestamp
                    })
            
            return history
```

### Context Formatting for LLM

```python
class ContextFormatter:
    """Formats chat history for optimal LLM consumption"""
    
    def format_for_agent(self, history: List[Dict], limit_tokens: int = 2000) -> str:
        """Format history within token limits"""
        
        formatted_parts = []
        total_tokens = 0
        
        # Recent messages have priority
        for msg in reversed(history):
            # Estimate tokens (rough: 4 chars per token)
            msg_tokens = len(msg["content"]) // 4
            
            if total_tokens + msg_tokens > limit_tokens:
                # Summarize older messages
                if len(formatted_parts) > 5:
                    summary = self.summarize_older_messages(history[:len(history)-len(formatted_parts)])
                    formatted_parts.insert(0, f"[Earlier conversation: {summary}]")
                break
            
            role = "User" if msg["role"] == "user" else "Valor"
            formatted_parts.append(f"{role}: {msg['content']}")
            total_tokens += msg_tokens
        
        return "\n".join(reversed(formatted_parts))
    
    def summarize_older_messages(self, messages: List[Dict]) -> str:
        """Create brief summary of older conversation"""
        
        topics = set()
        for msg in messages:
            # Extract key topics (simplified)
            if msg["role"] == "user":
                words = msg["content"].lower().split()
                topics.update([w for w in words if len(w) > 5])
        
        return f"Discussion about {', '.join(list(topics)[:3])}"
```

## Image and Media Handling

### Media Processing Pipeline

```python
class MediaHandler:
    """Comprehensive media processing with error recovery"""
    
    def __init__(self):
        self.download_dir = Path("temp/media")
        self.download_dir.mkdir(parents=True, exist_ok=True)
        self.max_file_size = 20 * 1024 * 1024  # 20MB
        
    async def process_media(self, message: Message, client: Client) -> Optional[str]:
        """Download and process media with comprehensive error handling"""
        
        try:
            # Determine media type and get file info
            media_type, file_info = self.identify_media(message)
            
            if not file_info:
                return None
            
            # Check file size
            if file_info.file_size > self.max_file_size:
                return f"‚ùå File too large ({file_info.file_size // (1024*1024)}MB, max 20MB)"
            
            # Generate unique filename
            file_ext = self.get_file_extension(file_info.mime_type, media_type)
            filename = f"{message.chat.id}_{message.id}_{int(time.time())}{file_ext}"
            file_path = self.download_dir / filename
            
            # Download with progress tracking
            await client.download_media(
                message,
                file_name=str(file_path),
                progress=self.download_progress
            )
            
            # Process based on media type
            if media_type == "photo":
                return await self.process_image(file_path)
            elif media_type == "document":
                return await self.process_document(file_path, file_info)
            elif media_type == "voice":
                return await self.process_voice(file_path)
            elif media_type == "video":
                return await self.process_video(file_path)
            
        except Exception as e:
            logger.error(f"Media processing error: {e}", exc_info=True)
            return f"‚ùå Failed to process media: {str(e)}"
        
        finally:
            # Cleanup downloaded file
            if 'file_path' in locals() and file_path.exists():
                try:
                    file_path.unlink()
                except:
                    pass
    
    async def process_image(self, file_path: Path) -> str:
        """Process image with AI analysis"""
        
        # Validate image format
        valid_formats = {'.jpg', '.jpeg', '.png', '.gif', '.webp'}
        if file_path.suffix.lower() not in valid_formats:
            return f"‚ùå Unsupported image format: {file_path.suffix}"
        
        try:
            # Basic image info
            from PIL import Image
            with Image.open(file_path) as img:
                width, height = img.size
                format_name = img.format
                
            info = f"üì∏ Image received: {width}x{height} {format_name}"
            
            # Trigger image analysis (will be handled by agent)
            return f"{info}\n\nImage saved for analysis: {file_path.name}"
            
        except Exception as e:
            return f"‚ùå Image processing error: {str(e)}"
```

### File Management and Cleanup

```python
class FileManager:
    """Manages temporary files with automatic cleanup"""
    
    def __init__(self):
        self.temp_dirs = [
            Path("temp/media"),
            Path("temp/documents"), 
            Path("temp/voice"),
            Path("temp/images")
        ]
        
        # Create directories
        for dir_path in self.temp_dirs:
            dir_path.mkdir(parents=True, exist_ok=True)
    
    def cleanup_old_files(self, max_age_hours: int = 24):
        """Remove files older than specified age"""
        
        cutoff_time = time.time() - (max_age_hours * 3600)
        
        for temp_dir in self.temp_dirs:
            for file_path in temp_dir.glob("*"):
                try:
                    if file_path.stat().st_mtime < cutoff_time:
                        file_path.unlink()
                        logger.debug(f"Cleaned up old file: {file_path}")
                except Exception as e:
                    logger.warning(f"Failed to cleanup {file_path}: {e}")
    
    def get_safe_filename(self, original_name: str, chat_id: int, message_id: int) -> str:
        """Generate safe, unique filename"""
        
        # Sanitize original name
        safe_name = re.sub(r'[^a-zA-Z0-9._-]', '_', original_name)
        safe_name = safe_name[:50]  # Limit length
        
        # Add unique identifier
        timestamp = int(time.time())
        return f"{chat_id}_{message_id}_{timestamp}_{safe_name}"
```

## Security and Validation

### Multi-Layer Security Architecture

```python
class SecurityGate:
    """Comprehensive security validation system"""
    
    def __init__(self):
        self.workspace_validator = WorkspaceValidator()
        self.rate_limiter = RateLimiter()
        self.access_controller = AccessController()
        
    def validate_access(self, message: Message) -> AccessResult:
        """Multi-layer security validation"""
        
        # Layer 1: Bot self-check
        if self.is_bot_message(message):
            return AccessResult(
                allowed=False,
                reason="Bot self-message",
                security_level="SYSTEM"
            )
        
        # Layer 2: Rate limiting
        if not self.rate_limiter.allow_message(message.from_user.id):
            return AccessResult(
                allowed=False, 
                reason="Rate limit exceeded (30 messages/60s)",
                security_level="RATE_LIMIT",
                retry_after=60
            )
        
        # Layer 3: Workspace access control
        workspace_access = self.workspace_validator.validate_chat_access(
            message.chat.id,
            message.from_user.id
        )
        
        if not workspace_access.allowed:
            return AccessResult(
                allowed=False,
                reason=workspace_access.denial_reason,
                security_level="WORKSPACE"
            )
        
        # Layer 4: Message validation
        if not self.validate_message_content(message):
            return AccessResult(
                allowed=False,
                reason="Message failed content validation",
                security_level="CONTENT"
            )
        
        # All checks passed
        return AccessResult(
            allowed=True,
            workspace=workspace_access.workspace,
            is_dev_group=workspace_access.is_dev_group,
            security_level="VALIDATED"
        )
```

### Access Control Implementation

```python
class AccessController:
    """Manages user and chat access permissions"""
    
    def __init__(self):
        self.config = self.load_workspace_config()
        
    def validate_dm_access(self, user_id: int, username: str) -> bool:
        """Check if user can send DMs"""
        
        # Check username whitelist
        allowed_users = self.config.get("dm_whitelist", {}).get("allowed_users", {})
        if username and username.lower() in allowed_users:
            return True
            
        # Check user ID whitelist
        allowed_ids = self.config.get("dm_whitelist", {}).get("allowed_user_ids", {})
        if str(user_id) in allowed_ids:
            return True
            
        return False
    
    def validate_group_access(self, chat_id: int) -> GroupAccess:
        """Check group access and permissions"""
        
        # Find workspace for chat
        for workspace_name, config in self.config.get("workspaces", {}).items():
            chat_ids = config.get("telegram_chat_ids", [])
            
            if chat_id in chat_ids:
                return GroupAccess(
                    allowed=True,
                    workspace=workspace_name,
                    is_dev_group=config.get("is_dev_group", False),
                    working_directory=config.get("working_directory", "")
                )
        
        # Check global allowed groups
        allowed_groups = os.getenv("TELEGRAM_ALLOWED_GROUPS", "").split(",")
        if str(chat_id) in allowed_groups:
            return GroupAccess(allowed=True, workspace="default")
            
        return GroupAccess(
            allowed=False,
            denial_reason=f"Chat {chat_id} not in allowed groups"
        )
```

### Input Sanitization

```python
class MessageSanitizer:
    """Sanitizes and validates message content"""
    
    def sanitize_text(self, text: str) -> str:
        """Clean and sanitize message text"""
        
        if not text:
            return ""
        
        # Remove null bytes and control characters
        text = re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]', '', text)
        
        # Normalize whitespace
        text = re.sub(r'\s+', ' ', text).strip()
        
        # Limit length
        if len(text) > 10000:
            text = text[:10000] + "... (truncated)"
        
        return text
    
    def validate_message_content(self, message: Message) -> bool:
        """Validate message content is safe"""
        
        # Check for suspicious patterns
        if message.text:
            suspicious_patterns = [
                r'<script[^>]*>.*?</script>',  # Script tags
                r'javascript:',                # Javascript URLs
                r'data:.*base64',             # Data URLs
            ]
            
            for pattern in suspicious_patterns:
                if re.search(pattern, message.text, re.IGNORECASE):
                    logger.warning(f"Suspicious pattern in message: {pattern}")
                    return False
        
        return True
```

## Configuration Patterns

### Workspace Configuration

```json
{
  "workspaces": {
    "Yudame Dev": {
      "database_id": "notion_database_id",
      "description": "Yudame development team tasks and management",
      "workspace_type": "yudame",
      "working_directory": "/Users/valorengels/src/ai",
      "telegram_chat_ids": ["-4891178445"],
      "aliases": ["yudame dev"],
      "is_dev_group": true
    },
    "PsyOPTIMAL": {
      "database_id": "notion_database_id_2", 
      "description": "PsyOPTIMAL team chat and project management",
      "workspace_type": "psyoptimal",
      "working_directory": "/Users/valorengels/src/psyoptimal",
      "telegram_chat_ids": ["-1002600253717"],
      "aliases": ["psyoptimal", "PO"],
      "is_dev_group": false
    }
  },
  "dm_whitelist": {
    "description": "Users allowed to send direct messages",
    "default_working_directory": "/Users/valorengels/src/ai",
    "allowed_users": {
      "tomcounsell": {
        "username": "tomcounsell",
        "description": "Tom Counsell - Owner and Boss",
        "working_directory": "/Users/valorengels/src/ai"
      },
      "valorengels": {
        "username": "valorengels", 
        "description": "Bot self - for system validation",
        "working_directory": "/Users/valorengels/src/ai"
      }
    },
    "allowed_user_ids": {
      "179144806": {
        "description": "Tom Counsell - Fallback access",
        "working_directory": "/Users/valorengels/src/ai"
      }
    }
  }
}
```

### Environment Configuration

```python
class TelegramConfig:
    """Centralized configuration management"""
    
    def __init__(self):
        self.api_id = self.get_required_env("TELEGRAM_API_ID", int)
        self.api_hash = self.get_required_env("TELEGRAM_API_HASH")
        self.bot_token = os.getenv("TELEGRAM_BOT_TOKEN")  # Optional
        
        # Access control
        self.allowed_groups = self.parse_allowed_groups()
        self.allow_dms = os.getenv("TELEGRAM_ALLOW_DMS", "false").lower() == "true"
        
        # Performance settings
        self.max_concurrent_handlers = int(os.getenv("MAX_CONCURRENT_HANDLERS", "5"))
        self.message_timeout = int(os.getenv("MESSAGE_TIMEOUT", "30"))
        self.download_timeout = int(os.getenv("DOWNLOAD_TIMEOUT", "60"))
        
    def get_required_env(self, key: str, type_converter=str):
        """Get required environment variable with type conversion"""
        value = os.getenv(key)
        if not value:
            raise ConfigurationError(f"Required environment variable {key} not set")
        
        try:
            return type_converter(value)
        except ValueError as e:
            raise ConfigurationError(f"Invalid value for {key}: {value}")
    
    def parse_allowed_groups(self) -> Set[int]:
        """Parse comma-separated allowed group IDs"""
        groups_str = os.getenv("TELEGRAM_ALLOWED_GROUPS", "")
        
        if not groups_str:
            return set()
            
        groups = set()
        for group_str in groups_str.split(","):
            try:
                groups.add(int(group_str.strip()))
            except ValueError:
                logger.warning(f"Invalid group ID in TELEGRAM_ALLOWED_GROUPS: {group_str}")
        
        return groups
```

## Advanced Features

### Sophisticated Reaction System

```python
class ReactionManager:
    """Manages sophisticated emoji reaction workflow"""
    
    # Complete set of valid Telegram reactions
    VALID_REACTIONS = {
        "üëç", "üëé", "‚ù§Ô∏è", "üî•", "ü•∞", "üëè", "üòÅ", "ü§î", "ü§Ø", "üò±", 
        "ü§¨", "üò¢", "üéâ", "ü§©", "ü§Æ", "üí©", "üôè", "üëå", "üïä", "ü§°",
        "ü•±", "ü•¥", "üòç", "üê≥", "‚ù§Ô∏è‚Äçüî•", "üåö", "üíØ", "ü§£", "‚ö°", "üçå",
        "üèÜ", "üíî", "ü§®", "üòê", "üçì", "üçæ", "üíã", "üñï", "üòà", "üò¥",
        "üò≠", "ü§ì", "üëª", "üë®‚Äçüíª", "üëÄ", "üéÉ", "üôà", "üòá", "üò®", "ü§ù",
        "‚úç", "ü§ó", "ü´°", "üéÖ", "üéÑ", "‚òÉÔ∏è", "üíÖ", "ü§™", "üóø", "üÜí",
        "üíò", "üôâ", "ü¶Ñ", "üòò", "üíä", "üôä", "üòé", "üëæ", "ü§∑‚Äç‚ôÇÔ∏è", "ü§∑",
        "ü§∑‚Äç‚ôÄÔ∏è", "üò°"
    }
    
    def __init__(self):
        self.reaction_history = {}  # Track reactions per message
        self.flood_wait_tracker = {}  # Track flood wait delays
        
    async def add_reaction(
        self, 
        client: Client, 
        chat_id: int, 
        message_id: int, 
        emoji: str
    ) -> bool:
        """Add reaction with flood wait handling"""
        
        # Validate emoji
        if emoji not in self.VALID_REACTIONS:
            logger.warning(f"Invalid reaction emoji: {emoji}")
            return False
        
        # Check if already reacted with this emoji
        reaction_key = f"{chat_id}_{message_id}_{emoji}"
        if reaction_key in self.reaction_history:
            return True  # Already added
        
        try:
            await client.send_reaction(
                chat_id=chat_id,
                message_id=message_id,
                emoji=emoji
            )
            
            # Track successful reaction
            self.reaction_history[reaction_key] = time.time()
            return True
            
        except FloodWait as e:
            # Handle flood wait
            wait_time = e.x
            logger.warning(f"Reaction flood wait: {wait_time}s")
            
            # Schedule retry after wait
            asyncio.create_task(self.retry_reaction_after_wait(
                client, chat_id, message_id, emoji, wait_time
            ))
            return False
            
        except Exception as e:
            logger.error(f"Reaction error: {e}")
            return False
    
    async def manage_reaction_workflow(
        self,
        client: Client,
        chat_id: int, 
        message_id: int,
        stage: ReactionStage
    ):
        """Manage 6-stage reaction workflow"""
        
        workflow_emojis = {
            ReactionStage.READ_RECEIPT: "üëÄ",
            ReactionStage.WORK_INDICATOR: "üë®‚Äçüíª",  # Context-dependent
            ReactionStage.PROGRESS: "‚è≥", 
            ReactionStage.SUCCESS: "üëç",
            ReactionStage.ERROR: "‚ùå",
            ReactionStage.RECOVERY: "ü§ù"
        }
        
        emoji = workflow_emojis.get(stage)
        if emoji:
            await self.add_reaction(client, chat_id, message_id, emoji)
```

### Error Recovery System

```python
class ErrorRecoverySystem:
    """Automated error recovery with Claude Code integration"""
    
    def __init__(self):
        self.recovery_attempts = {}  # Track recovery attempts
        self.max_recovery_attempts = 3
        
    async def handle_error(
        self, 
        error: Exception, 
        context: Dict[str, Any]
    ) -> RecoveryResult:
        """Analyze error and attempt recovery"""
        
        error_key = f"{type(error).__name__}_{hash(str(error))}"
        attempts = self.recovery_attempts.get(error_key, 0)
        
        if attempts >= self.max_recovery_attempts:
            return RecoveryResult(
                recovered=False,
                reason="Maximum recovery attempts exceeded",
                give_up=True
            )
        
        # Analyze error type
        recovery_strategy = self.analyze_error(error, context)
        
        if recovery_strategy:
            self.recovery_attempts[error_key] = attempts + 1
            
            # Execute recovery
            result = await self.execute_recovery(recovery_strategy, context)
            
            if result.recovered:
                # Reset counter on success
                self.recovery_attempts.pop(error_key, None)
            
            return result
        
        return RecoveryResult(recovered=False, reason="No recovery strategy available")
    
    def analyze_error(self, error: Exception, context: Dict) -> Optional[RecoveryStrategy]:
        """Analyze error and determine recovery approach"""
        
        error_patterns = {
            "database is locked": RecoveryStrategy.DATABASE_RETRY,
            "connection timeout": RecoveryStrategy.NETWORK_RETRY,
            "rate limit": RecoveryStrategy.BACKOFF_RETRY,
            "import error": RecoveryStrategy.DEPENDENCY_FIX,
            "permission denied": RecoveryStrategy.PERMISSION_FIX
        }
        
        error_text = str(error).lower()
        
        for pattern, strategy in error_patterns.items():
            if pattern in error_text:
                return strategy
                
        return None
```

## Performance Optimization

### Connection Pooling

```python
class ConnectionPool:
    """Manages database connections efficiently"""
    
    def __init__(self, max_connections: int = 5):
        self.pool = asyncio.Queue(maxsize=max_connections)
        self.max_connections = max_connections
        self._created_connections = 0
        
    async def get_connection(self) -> aiosqlite.Connection:
        """Get connection from pool or create new one"""
        
        try:
            # Try to get existing connection
            connection = self.pool.get_nowait()
            return connection
        except asyncio.QueueEmpty:
            # Create new connection if under limit
            if self._created_connections < self.max_connections:
                connection = await aiosqlite.connect("system.db")
                self._created_connections += 1
                return connection
            else:
                # Wait for connection to be available
                return await self.pool.get()
    
    async def return_connection(self, connection: aiosqlite.Connection):
        """Return connection to pool"""
        try:
            self.pool.put_nowait(connection)
        except asyncio.QueueFull:
            # Pool is full, close connection
            await connection.close()
            self._created_connections -= 1
```

### Message Batching

```python
class MessageBatcher:
    """Batches multiple messages for efficient processing"""
    
    def __init__(self, batch_size: int = 5, batch_timeout: float = 1.0):
        self.batch_size = batch_size
        self.batch_timeout = batch_timeout
        self.pending_messages = []
        self.last_batch_time = time.time()
        
    async def add_message(self, message: Message, client: Client):
        """Add message to batch or process immediately"""
        
        self.pending_messages.append((message, client))
        
        # Check if we should process batch
        should_process = (
            len(self.pending_messages) >= self.batch_size or
            time.time() - self.last_batch_time > self.batch_timeout
        )
        
        if should_process:
            await self.process_batch()
    
    async def process_batch(self):
        """Process all messages in current batch"""
        
        if not self.pending_messages:
            return
            
        batch = self.pending_messages.copy()
        self.pending_messages.clear()
        self.last_batch_time = time.time()
        
        # Process messages concurrently
        tasks = []
        for message, client in batch:
            task = asyncio.create_task(
                self.process_single_message(message, client)
            )
            tasks.append(task)
        
        # Wait for all to complete
        await asyncio.gather(*tasks, return_exceptions=True)
```

## Integration with Main System

### Startup Integration

```python
class TelegramIntegrationManager:
    """Manages Telegram integration lifecycle"""
    
    def __init__(self, main_app):
        self.main_app = main_app
        self.telegram_client = None
        self.integration_health = "UNKNOWN"
        
    async def start_integration(self):
        """Start Telegram integration with health monitoring"""
        
        try:
            # Initialize client
            self.telegram_client = TelegramClient()
            
            # Start client
            await self.telegram_client.start()
            
            # Perform health check
            health_result = await self.perform_health_check()
            
            if health_result.healthy:
                self.integration_health = "HEALTHY"
                logger.info("‚úÖ Telegram integration started successfully")
            else:
                self.integration_health = "DEGRADED"
                logger.warning(f"‚ö†Ô∏è Telegram integration started with issues: {health_result.issues}")
                
        except Exception as e:
            self.integration_health = "FAILED"
            logger.error(f"‚ùå Telegram integration failed to start: {e}")
            raise
    
    async def perform_health_check(self) -> HealthCheckResult:
        """Comprehensive health check"""
        
        checks = [
            self.check_client_connection(),
            self.check_message_processing(),
            self.check_database_access(),
            self.check_workspace_config(),
        ]
        
        results = await asyncio.gather(*checks, return_exceptions=True)
        
        issues = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                issues.append(f"Check {i} failed: {result}")
            elif not result:
                issues.append(f"Check {i} failed")
        
        return HealthCheckResult(
            healthy=len(issues) == 0,
            issues=issues
        )
```

## Testing Strategy

### Integration Testing

```python
class TestTelegramIntegration:
    """Comprehensive integration tests"""
    
    @pytest.fixture
    async def mock_client(self):
        """Mock Telegram client for testing"""
        client = Mock()
        client._active_handlers = set()
        return client
    
    async def test_message_pipeline(self, mock_client):
        """Test complete message processing pipeline"""
        
        processor = UnifiedMessageProcessor()
        
        # Create test message
        message = Mock()
        message.chat.id = 123456
        message.id = 789
        message.from_user.id = 111
        message.from_user.username = "testuser"
        message.text = "Hello, how are you?"
        message.date = datetime.now()
        
        # Process message
        result = await processor.process_message(mock_client, message)
        
        # Verify processing
        assert isinstance(result, ProcessingResult)
        # Add more specific assertions
    
    async def test_error_recovery(self, mock_client):
        """Test error recovery mechanisms"""
        
        processor = UnifiedMessageProcessor()
        
        # Mock component failure
        processor.agent_orchestrator.process_with_agent = Mock(
            side_effect=Exception("Test error")
        )
        
        # Process message (should not raise)
        await processor.process_message(mock_client, Mock())
        
        # Verify error was handled gracefully
        # Add assertions for error handling
```

## Security Considerations

### Authentication Security

- **API Credentials**: Stored in environment variables, never in code
- **Session Security**: Sessions isolated in dedicated directory
- **Access Control**: Multi-layer validation with workspace isolation
- **Rate Limiting**: Prevents abuse with configurable limits

### Data Security

- **Message Storage**: Encrypted database connection
- **File Management**: Automatic cleanup of temporary files
- **Input Sanitization**: All user input sanitized and validated
- **Audit Logging**: Comprehensive logging of security events

### Network Security

- **TLS/SSL**: All connections use encryption
- **API Rate Limits**: Respect Telegram API limits
- **Retry Logic**: Exponential backoff prevents hammering
- **Connection Resilience**: Automatic reconnection with limits

## Conclusion

The Telegram integration system provides a robust, secure, and feature-rich interface for users to interact with the AI system. Through its sophisticated 5-step processing pipeline, advanced reaction system, comprehensive error recovery, and multi-layer security architecture, it delivers a seamless user experience while maintaining high reliability and performance standards.

Key strengths:
- **91% complexity reduction** through modular architecture
- **Sophisticated emoji workflow** for enhanced UX
- **Comprehensive error recovery** with automated solutions
- **Multi-layer security** with workspace isolation
- **Production-ready features** like connection pooling and batching
- **Extensive testing** support through modular design

This architecture serves as a solid foundation for conversational AI interaction while providing the scalability and maintainability needed for production deployment.