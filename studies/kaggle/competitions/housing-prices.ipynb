{"cells":[{"metadata":{},"cell_type":"markdown","source":"**[Introduction to Machine Learning Home Page](https://www.kaggle.com/learn/intro-to-machine-learning)**\n\n---\n"},{"metadata":{},"cell_type":"markdown","source":"# Housing Prices from [Kaggle's Intro to ML](https://www.kaggle.com/learn/intro-to-machine-learning)\n"},{"metadata":{},"cell_type":"markdown","source":"## Setup"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Code you have previously used to load data\nimport numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor\n\n# Set up code checking\nimport os\nif not os.path.exists(\"../input/train.csv\"):\n    os.symlink(\"../input/home-data-for-ml-course/train.csv\", \"../input/train.csv\")  \n    os.symlink(\"../input/home-data-for-ml-course/test.csv\", \"../input/test.csv\") \nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.machine_learning.ex7 import *\n\n# read train and test data files using pandas\ntrain_data_file_path = '../input/train.csv'\noriginal_home_data = pd.read_csv(train_data_file_path)\n\ntest_data_file_path = '../input/test.csv'\ntest_data = pd.read_csv(test_data_file_path)\n\n\ntrain_data = original_home_data.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# correlations = home_data.corr()\n# correlations.SalePrice.sort_values()\n\n## Inspect the data and come back anytime to review\n\ntrain_data.head()\n# train_data.head()\n# train_data.describe()\n# train_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def home_data_handle_na(home_data):\n    # Columns where 'NaN' means None\n    none_cols = [\n        'Alley', 'PoolQC', 'MiscFeature', 'Fence', 'FireplaceQu', 'GarageType',\n        'GarageFinish', 'GarageQual', 'GarageCond', 'BsmtQual', 'BsmtCond',\n        'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'MasVnrType'\n    ]\n    for col in none_cols:\n        home_data[col].replace(np.nan, 'None', inplace=True)\n\n    # Columns where 'NaN' means 0\n    zero_cols = [\n        'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath',\n        'BsmtHalfBath', 'GarageYrBlt', 'GarageArea', 'GarageCars', 'MasVnrArea'\n    ]\n    for col in zero_cols:\n        home_data[col].replace(np.nan, 0, inplace=True)\n\n    # Columns where 'NaN' can be replaced with mode\n    freq_cols = [\n        'Electrical', 'Exterior1st', 'Exterior2nd', 'Functional', 'KitchenQual',\n        'SaleType', 'Utilities'\n    ]\n    for col in freq_cols:\n        home_data[col].replace(np.nan, home_data[col].mode()[0], inplace=True)\n\n    # Filling 'MSZoning' according to MSSubClass.\n    home_data['MSZoning'] = home_data.groupby('MSSubClass')['MSZoning'].apply(\n        lambda x: x.fillna(x.mode()[0]))\n\n    # Filling 'MSZoning' according to Neighborhood.\n    home_data['LotFrontage'] = home_data.groupby(\n        ['Neighborhood'])['LotFrontage'].apply(lambda x: x.fillna(x.median()))\n\n    # home_data which numerical on data but should be treated as category:\n    home_data['MSSubClass'] = home_data['MSSubClass'].astype(str)\n    home_data['YrSold'] = home_data['YrSold'].astype(str)\n    home_data['MoSold'] = home_data['MoSold'].astype(str)\n\n    # Transforming rare values(less than 10) into one group.\n    other_cols = [\n        'Condition1', 'Condition2', 'RoofMatl', 'Exterior1st', 'Exterior2nd',\n        'Heating', 'Electrical', 'Functional', 'SaleType'\n    ]\n    for col in other_cols:\n        mask = home_data[col].isin(\n            home_data[col].value_counts()[home_data[col].value_counts() < 10].index)\n        home_data[col][mask] = 'Other'\n\n    # Converting some of the categorical values to numeric ones.\n    neigh_map = {\n        'MeadowV': 1, 'IDOTRR': 1, 'BrDale': 1,\n        'BrkSide': 2, 'OldTown': 2, 'Edwards': 2,\n        'Sawyer': 3, 'Blueste': 3, 'SWISU': 3, 'NPkVill': 3, 'NAmes': 3,\n        'Mitchel': 4,\n        'SawyerW': 5, 'NWAmes': 5, 'Gilbert': 5, 'Blmngtn': 5,\n        'CollgCr': 6, 'ClearCr': 6, 'Crawfor': 6,\n        'Veenker': 7, 'Somerst': 7,\n        'Timber': 8, 'StoneBr': 9, 'NridgHt': 10, 'NoRidge': 10\n    }\n    home_data['Neighborhood'] = home_data['Neighborhood'].map(neigh_map).astype(\n        'int')\n    ext_map = {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\n    home_data['ExterQual'] = home_data['ExterQual'].map(ext_map).astype('int')\n    home_data['ExterCond'] = home_data['ExterCond'].map(ext_map).astype('int')\n    bsm_map = {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\n    home_data['BsmtQual'] = home_data['BsmtQual'].map(bsm_map).astype('int')\n    home_data['BsmtCond'] = home_data['BsmtCond'].map(bsm_map).astype('int')\n    bsmf_map = {\n        'None': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6\n    }\n    home_data['BsmtFinType1'] = home_data['BsmtFinType1'].map(bsmf_map).astype('int')\n    home_data['BsmtFinType2'] = home_data['BsmtFinType2'].map(bsmf_map).astype('int')\n    heat_map = {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\n    home_data['HeatingQC'] = home_data['HeatingQC'].map(heat_map).astype('int')\n    home_data['KitchenQual'] = home_data['KitchenQual'].map(heat_map).astype('int')\n    home_data['FireplaceQu'] = home_data['FireplaceQu'].map(bsm_map).astype('int')\n    home_data['GarageCond'] = home_data['GarageCond'].map(bsm_map).astype('int')\n    home_data['GarageQual'] = home_data['GarageQual'].map(bsm_map).astype('int')\n\n    return home_data\n\n\ntrain_data = home_data_handle_na(train_data)\ntest_data = home_data_handle_na(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping outliers after detecting them by eye.\n\ndef home_data_handle_outliers(home_data):\n    \n    home_data = home_data.drop(home_data[(home_data['OverallQual'] < 5) & (home_data['SalePrice'] > 200000)].index)\n    home_data = home_data.drop(home_data[(home_data['OverallQual'] > 7) & (home_data['SalePrice'] > 420000)].index)\n    home_data = home_data.drop(home_data[(home_data['OverallQual'] > 8) & (home_data['SalePrice'] < 250000)].index)\n\n    home_data = home_data.drop(home_data[(home_data['GrLivArea'] > 4000) & (home_data['SalePrice'] < 320000)].index)\n\n    home_data = home_data.drop(home_data[(home_data['GarageArea'] > 1200) & (home_data['SalePrice'] < 200000)].index)\n\n    home_data = home_data.drop(home_data[(home_data['TotalBsmtSF'] > 3000) & (home_data['SalePrice'] < 320000)].index)\n\n    home_data = home_data.drop(home_data[(home_data['1stFlrSF'] < 3000) & (home_data['SalePrice'] > 640000)].index)\n    home_data = home_data.drop(home_data[(home_data['1stFlrSF'] > 3000) & (home_data['SalePrice'] < 240000)].index)\n    return home_data\n\n\ntrain_data = home_data_handle_outliers(train_data)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def home_data_add_insights(home_data):\n    # Creating new home_data  based on previous observations. There might be some highly correlated home_data now. Drop them if you want to...\n\n    home_data['TotalSF'] = (\n        home_data['BsmtFinSF1'] + home_data['BsmtFinSF2'] + \n        home_data['1stFlrSF'] + home_data['2ndFlrSF']\n    )\n    home_data['TotalBathrooms'] = (\n        home_data['FullBath'] + home_data['BsmtFullBath'] + \n        (0.8 * (home_data['HalfBath'] + home_data['BsmtHalfBath']))\n    )\n\n    home_data['TotalPorchSF'] = (\n        home_data['OpenPorchSF'] + home_data['3SsnPorch'] + home_data['EnclosedPorch'] + \n        home_data['ScreenPorch'] + home_data['WoodDeckSF']\n    )\n\n    # home_data['YearBlRm'] = (home_data['YearBuilt'] + home_data['YearRemodAdd'])\n\n    # Merging quality and conditions.\n\n    home_data['TotalExtQual'] = (home_data['ExterQual'] + home_data['ExterCond'])\n    home_data['TotalBsmQual'] = (\n        home_data['BsmtQual'] + home_data['BsmtCond'] + home_data['BsmtFinType1'] + home_data['BsmtFinType2']\n    )\n    home_data['TotalGrgQual'] = (home_data['GarageQual'] + home_data['GarageCond'])\n    home_data['TotalQual'] = (\n        home_data['OverallQual'] + home_data['TotalExtQual'] + \n        home_data['TotalBsmQual'] + home_data['TotalGrgQual'] + \n        home_data['KitchenQual'] + home_data['HeatingQC']\n    )\n\n    # Creating new home_data by using new quality indicators.\n\n    home_data['QualGr'] = home_data['TotalQual'] * home_data['GrLivArea']\n    home_data['QualBsm'] = home_data['TotalBsmQual'] * (home_data['BsmtFinSF1'] + home_data['BsmtFinSF2'])\n    home_data['QualPorch'] = home_data['TotalExtQual'] * home_data['TotalPorchSF']\n    home_data['QualExt'] = home_data['TotalExtQual'] * home_data['MasVnrArea']\n    home_data['QualGrg'] = home_data['TotalGrgQual'] * home_data['GarageArea']\n    home_data['QlLivArea'] = (home_data['GrLivArea'] - home_data['LowQualFinSF']) * (home_data['TotalQual'])\n    home_data['QualSFNg'] = home_data['QualGr'] * home_data['Neighborhood']\n\n    return home_data\n\n\ntrain_data = home_data_add_insights(train_data)\ntest_data = home_data_add_insights(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def home_data_add_bool_insights(home_data):\n    home_data['HasPool'] = home_data['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n    home_data['Has2ndFloor'] = home_data['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n    home_data['HasGarage'] = home_data['QualGrg'].apply(lambda x: 1 if x > 0 else 0)\n    home_data['HasBsmt'] = home_data['QualBsm'].apply(lambda x: 1 if x > 0 else 0)\n    home_data['HasFireplace'] = home_data['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n    home_data['HasPorch'] = home_data['QualPorch'].apply(lambda x: 1 if x > 0 else 0)\n    return home_data\n\ntrain_data = home_data_add_bool_insights(train_data)\ntest_data = home_data_add_bool_insights(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def home_data_drop_features(home_data):\n    # Dropping features.\n    home_data.drop(columns=[\n        'Utilities',\n        'PoolQC',\n        'YrSold',\n        'MoSold',\n        'ExterQual',\n        'BsmtQual',\n        'GarageQual',\n        'KitchenQual',\n        'HeatingQC',\n    ], inplace=True)\n\n    return home_data\n\n\ntrain_data = home_data_drop_features(train_data)\ntest_data = home_data_drop_features(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Number of missing values: {train_data.isna().sum().sum()}')\nprint(f'Number of missing values: {test_data.isna().sum().sum()}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create target object and call it y\ny = train_data['SalePrice']\ny.dropna(inplace=True)\n\n# Create X\nfeatures = ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', '1stFlrSF', 'FullBath', 'TotRmsAbvGrd', 'YearBuilt', 'YearRemodAdd', 'WoodDeckSF', 'ScreenPorch']\nfeatures += ['TotalSF', 'TotalBathrooms', 'TotalPorchSF', 'TotalExtQual', 'TotalBsmQual', 'TotalGrgQual', 'TotalQual'] \nfeatures += ['QualGr', 'QualBsm', 'QualPorch', 'QualExt', 'QualGrg', 'QlLivArea', 'QualSFNg'] \nfeatures += ['HasPool', 'Has2ndFloor', 'HasGarage', 'HasBsmt', 'HasFireplace', 'HasPorch']\nX = train_data[features]\n\n# Split into validation and training data\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n\n# Specify Model\niowa_model = DecisionTreeRegressor(random_state=1)\n# Fit Model\niowa_model.fit(train_X, train_y)\n\n# Make validation predictions and calculate mean absolute error\nval_predictions = iowa_model.predict(val_X)\nval_mae = mean_absolute_error(val_predictions, val_y)\nprint(\"Validation MAE when not specifying max_leaf_nodes: {:,.0f}\".format(val_mae))\n\n# Using best value for max_leaf_nodes\niowa_model = DecisionTreeRegressor(max_leaf_nodes=100, random_state=1)\niowa_model.fit(train_X, train_y)\nval_predictions = iowa_model.predict(val_X)\nval_mae = mean_absolute_error(val_predictions, val_y)\nprint(\"Validation MAE for best value of max_leaf_nodes: {:,.0f}\".format(val_mae))\n\n# Define the model. Set random_state to 1\nrf_model = RandomForestRegressor(random_state=1)\nrf_model.fit(train_X, train_y)\nrf_val_predictions = rf_model.predict(val_X)\nrf_val_mae = mean_absolute_error(rf_val_predictions, val_y)\n\nprint(\"Validation MAE for Random Forest Model: {:,.0f}\".format(rf_val_mae))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating a Model For the Competition\n\nBuild a Random Forest model and train it on all of **X** and **y**."},{"metadata":{"trusted":true},"cell_type":"code","source":"# To improve accuracy, create a new Random Forest model which you will train on all training data\nrf_model_on_full_data = RandomForestRegressor(random_state=1)\n\n# fit rf_model_on_full_data on all data from the training data\nrf_model.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Make Predictions\nRead the file of \"test\" data. And apply your model to make predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# create test_X which comes from test_data but includes only the columns you used for prediction.\n# The list of columns is stored in a variable called features\ntest_X = test_data[features]\n\n# make predictions which we will submit. \ntest_preds = rf_model.predict(test_X)\n\n# The lines below shows how to save predictions in format used for competition scoring\n# Just uncomment them.\n\noutput = pd.DataFrame({'Id': test_data.Id,\n                      'SalePrice': test_preds})\noutput.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before submitting, run a check to make sure your `test_preds` have the right format."},{"metadata":{},"cell_type":"markdown","source":"# Test Your Work\n\nTo test your results, you'll need to join the competition (if you haven't already).  So open a new window by clicking on [this link](https://www.kaggle.com/c/home-data-for-ml-course).  Then click on the **Join Competition** button.\n\n![join competition image](https://i.imgur.com/wLmFtH3.png)\n\nNext, follow the instructions below:\n1. Begin by clicking on the blue **Save Version** button in the top right corner of the window.  This will generate a pop-up window.  \n2. Ensure that the **Save and Run All** option is selected, and then click on the blue **Save** button.\n3. This generates a window in the bottom left corner of the notebook.  After it has finished running, click on the number to the right of the **Save Version** button.  This pulls up a list of versions on the right of the screen.  Click on the ellipsis **(...)** to the right of the most recent version, and select **Open in Viewer**.  This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.\n4. Click on the **Output** tab on the right of the screen.  Then, click on the blue **Submit** button to submit your results to the leaderboard.\n\nYou have now successfully submitted to the competition!\n\nIf you want to keep working to improve your performance, select the blue **Edit** button in the top right of the screen. Then you can change your code and repeat the process. There's a lot of room to improve, and you will climb up the leaderboard as you work.\n\n\n# Continuing Your Progress\nThere are many ways to improve your model, and **experimenting is a great way to learn at this point.**\n\nThe best way to improve your model is to add features.  Look at the list of columns and think about what might affect home prices.  Some features will cause errors because of issues like missing values or non-numeric data types. \n\nThe **[Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning)** micro-course will teach you how to handle these types of features. You will also learn to use **xgboost**, a technique giving even better accuracy than Random Forest.\n\n\n# Other Micro-Courses\nThe **[Pandas](https://kaggle.com/Learn/Pandas)** micro-course will give you the data manipulation skills to quickly go from conceptual idea to implementation in your data science projects. \n\nYou are also ready for the **[Deep Learning](https://kaggle.com/Learn/Deep-Learning)** micro-course, where you will build models with better-than-human level performance at computer vision tasks."},{"metadata":{},"cell_type":"markdown","source":"---\n**[Introduction to Machine Learning Home Page](https://www.kaggle.com/learn/intro-to-machine-learning)**\n\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum/161285) to chat with other Learners.*"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}